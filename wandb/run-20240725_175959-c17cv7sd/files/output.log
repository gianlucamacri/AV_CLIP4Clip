07/25/2024 18:00:01 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 18:00:01 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 18:00:01 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 18:00:01 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 18:00:01 - WARNING -   Test retrieval by loose type.
07/25/2024 18:00:01 - WARNING -   	 embed_dim: 512
07/25/2024 18:00:01 - WARNING -   	 image_resolution: 224
07/25/2024 18:00:01 - WARNING -   	 vision_layers: 12
07/25/2024 18:00:01 - WARNING -   	 vision_width: 768
07/25/2024 18:00:01 - WARNING -   	 vision_patch_size: 32
07/25/2024 18:00:01 - WARNING -   	 context_length: 77
07/25/2024 18:00:01 - WARNING -   	 vocab_size: 49408
07/25/2024 18:00:01 - WARNING -   	 transformer_width: 512
07/25/2024 18:00:01 - WARNING -   	 transformer_heads: 8
07/25/2024 18:00:01 - WARNING -   	 transformer_layers: 12
07/25/2024 18:00:01 - WARNING -   		 linear_patch: 2d
07/25/2024 18:00:01 - WARNING -   	 cut_top_layer: 0
07/25/2024 18:00:02 - WARNING -   	 sim_header: meanP
07/25/2024 18:00:05 - INFO -   --------------------
07/25/2024 18:00:05 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 18:00:06 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:00:06 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:00:06 - INFO -   ***** Running test *****
07/25/2024 18:00:06 - INFO -     Num examples = 24
07/25/2024 18:00:06 - INFO -     Batch size = 16
07/25/2024 18:00:06 - INFO -     Num steps = 2
07/25/2024 18:00:06 - INFO -   ***** Running val *****
07/25/2024 18:00:06 - INFO -     Num examples = 6
07/25/2024 18:00:06 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:00:06 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 18:00:06 - INFO -   ***** Running training *****
07/25/2024 18:00:06 - INFO -     Num examples = 90
07/25/2024 18:00:06 - INFO -     Batch size = 36
07/25/2024 18:00:06 - INFO -     Num steps = 50




100%|███████████████████████████████████████████| 5/5 [00:37<00:00,  7.44s/it]
07/25/2024 18:00:44 - INFO -   Epoch 1/10 Finished, Train Loss: 0.495020
07/25/2024 18:00:44 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.0
07/25/2024 18:00:44 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_opt.bin.0
07/25/2024 18:00:44 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:00:47 - INFO -   retrieval of video 16 took 2.277441140031442
07/25/2024 18:00:47 - INFO -   computation took 0.049431002931669354
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.33s/it]
07/25/2024 18:00:48 - INFO -   sim matrix size: 6, 6
07/25/2024 18:00:48 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:00:48 - INFO -   Similarity loss: 1.4
07/25/2024 18:00:48 - INFO -   Text-to-Video:
07/25/2024 18:00:48 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:00:48 - INFO -   Video-to-Text:
07/25/2024 18:00:48 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:00:48 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.0, its metric is: 1.4236




100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.30s/it]
07/25/2024 18:01:24 - INFO -   Epoch 2/10 Finished, Train Loss: 0.520419
07/25/2024 18:01:25 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.1
07/25/2024 18:01:25 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_opt.bin.1
07/25/2024 18:01:25 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:01:28 - INFO -   retrieval of video 16 took 2.380339734023437
07/25/2024 18:01:28 - INFO -   computation took 0.05085640400648117
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.43s/it]
07/25/2024 18:01:28 - INFO -   sim matrix size: 6, 6
07/25/2024 18:01:28 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:01:28 - INFO -   Similarity loss: 1.4
07/25/2024 18:01:28 - INFO -   Text-to-Video:
07/25/2024 18:01:28 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:01:28 - INFO -   Video-to-Text:
07/25/2024 18:01:28 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:01:28 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.1, its metric is: 1.4053




100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.29s/it]
07/25/2024 18:02:04 - INFO -   Epoch 3/10 Finished, Train Loss: 0.342839
07/25/2024 18:02:05 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.2
07/25/2024 18:02:05 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_opt.bin.2
07/25/2024 18:02:05 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:02:08 - INFO -   retrieval of video 16 took 2.349356333957985
07/25/2024 18:02:08 - INFO -   computation took 0.049070632085204124
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]
07/25/2024 18:02:08 - INFO -   sim matrix size: 6, 6
07/25/2024 18:02:08 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:02:08 - INFO -   Similarity loss: 1.4
07/25/2024 18:02:08 - INFO -   Text-to-Video:
07/25/2024 18:02:08 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:02:08 - INFO -   Video-to-Text:
07/25/2024 18:02:08 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:02:08 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.2, its metric is: 1.3824




100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.25s/it]
07/25/2024 18:02:44 - INFO -   Epoch 4/10 Finished, Train Loss: 0.262590
07/25/2024 18:02:45 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.3
07/25/2024 18:02:45 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_opt.bin.3
07/25/2024 18:02:45 - INFO -   Eval on val dataset
07/25/2024 18:02:47 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 18:02:47 - INFO -   retrieval of video 16 took 2.352971288957633
07/25/2024 18:02:47 - INFO -   computation took 0.048110089963302016
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]
07/25/2024 18:02:47 - INFO -   sim matrix size: 6, 6
07/25/2024 18:02:47 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 18:02:47 - INFO -   retrieval of video 16 took 2.352971288957633
07/25/2024 18:02:47 - INFO -   Similarity loss: 1.4
07/25/2024 18:02:47 - INFO -   Text-to-Video:
07/25/2024 18:02:47 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:02:47 - INFO -   Video-to-Text:
07/25/2024 18:02:47 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:02:47 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.3, its metric is: 1.3714
 20%|████████▌                                  | 1/5 [00:06<00:27,  6.94s/it]
 40%|█████████████████▏                         | 2/5 [00:14<00:21,  7.04s/it]
 60%|█████████████████████████▊                 | 3/5 [00:22<00:15,  7.83s/it]
 80%|██████████████████████████████████▍        | 4/5 [00:28<00:07,  7.16s/it]
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.28s/it]
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.28s/it]
07/25/2024 18:03:27 - INFO -   Text-to-Video:███| 5/5 [00:36<00:00,  7.28s/it]
07/25/2024 18:03:27 - INFO -   Text-to-Video:███| 5/5 [00:36<00:00,  7.28s/it]
07/25/2024 18:03:27 - INFO -   Text-to-Video:███| 5/5 [00:36<00:00,  7.28s/it]
07/25/2024 18:03:27 - INFO -   Text-to-Video:███| 5/5 [00:36<00:00,  7.28s/it]
07/25/2024 18:03:27 - INFO -   Text-to-Video:███| 5/5 [00:36<00:00,  7.28s/it]
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.29s/it]
07/25/2024 18:04:05 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.5
  0%|                                                   | 0/5 [00:00<?, ?it/s]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
 20%|████████▌                                  | 1/5 [00:06<00:27,  7.00s/it]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
 40%|█████████████████▏                         | 2/5 [00:14<00:22,  7.48s/it]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
 60%|█████████████████████████▊                 | 3/5 [00:22<00:14,  7.43s/it]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
 80%|██████████████████████████████████▍        | 4/5 [00:29<00:07,  7.22s/it]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.24s/it]07/25/2024 18:04:07 - INFO -   retrieval of video 16 took 2.3160283969482407
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.24s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
07/25/2024 18:04:47 - INFO -   sim matrix size: 6, 65 [00:36<00:00,  7.24s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
 20%|████████▌                                  | 1/5 [00:06<00:24,  6.07s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
 40%|█████████████████▏                         | 2/5 [00:14<00:22,  7.42s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
 60%|█████████████████████████▊                 | 3/5 [00:21<00:14,  7.39s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
 80%|██████████████████████████████████▍        | 4/5 [00:29<00:07,  7.50s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
100%|███████████████████████████████████████████| 5/5 [00:35<00:00,  7.16s/it]07/25/2024 18:04:46 - INFO -   retrieval of video 16 took 2.2398933029035106
07/25/2024 18:05:23 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.7ok 2.2398933029035106
  0%|                                                   | 0/5 [00:00<?, ?it/s]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
 20%|████████▌                                  | 1/5 [00:06<00:25,  6.50s/it]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
 40%|█████████████████▏                         | 2/5 [00:16<00:25,  8.33s/it]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
 60%|█████████████████████████▊                 | 3/5 [00:22<00:15,  7.64s/it]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
 80%|██████████████████████████████████▍        | 4/5 [00:30<00:07,  7.56s/it]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
100%|███████████████████████████████████████████| 5/5 [00:36<00:00,  7.26s/it]07/25/2024 18:05:26 - INFO -   retrieval of video 16 took 2.3533816389972344
07/25/2024 18:06:03 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.8ok 2.3533816389972344
  0%|                                                   | 0/5 [00:00<?, ?it/s]07/25/2024 18:06:05 - INFO -   retrieval of video 16 took 2.3458472290076315
 20%|████████▌                                  | 1/5 [00:07<00:29,  7.49s/it]07/25/2024 18:06:05 - INFO -   retrieval of video 16 took 2.3458472290076315
 40%|█████████████████▏                         | 2/5 [00:14<00:22,  7.42s/it]07/25/2024 18:06:05 - INFO -   retrieval of video 16 took 2.3458472290076315
 60%|█████████████████████████▊                 | 3/5 [00:22<00:14,  7.33s/it]07/25/2024 18:06:05 - INFO -   retrieval of video 16 took 2.3458472290076315
 80%|██████████████████████████████████▍        | 4/5 [00:30<00:07,  7.56s/it]07/25/2024 18:06:05 - INFO -   retrieval of video 16 took 2.3458472290076315
 80%|██████████████████████████████████▍        | 4/5 [00:30<00:07,  7.56s/it]07/25/2024 18:06:42 - INFO -   Epoch: 10/10, Step: 5/5, Lr: , Loss: 0.132660, Time/step: 0.727379
07/25/2024 18:06:43 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b36_50fps_loss_42_1721923198_test/pytorch_model.bin.9 Lr: , Loss: 0.132660, Time/step: 0.727379
07/25/2024 18:06:46 - WARNING -   	 image_resolution: 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:06:47 - WARNING -   	 sim_header: meanP 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:06:47 - WARNING -   	 sim_header: meanP 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

0/2

07/25/2024 18:06:59 - INFO -   sim matrix size: 24, 24224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:06:59 - INFO -   sim matrix size: 24, 24224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.