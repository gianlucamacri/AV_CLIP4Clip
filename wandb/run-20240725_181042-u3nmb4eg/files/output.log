07/25/2024 18:10:44 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 18:10:44 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 18:10:44 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 18:10:44 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 18:10:44 - WARNING -   Test retrieval by loose type.
07/25/2024 18:10:44 - WARNING -   	 embed_dim: 512
07/25/2024 18:10:44 - WARNING -   	 image_resolution: 224
07/25/2024 18:10:44 - WARNING -   	 vision_layers: 12
07/25/2024 18:10:44 - WARNING -   	 vision_width: 768
07/25/2024 18:10:44 - WARNING -   	 vision_patch_size: 16
07/25/2024 18:10:44 - WARNING -   	 context_length: 77
07/25/2024 18:10:44 - WARNING -   	 vocab_size: 49408
07/25/2024 18:10:44 - WARNING -   	 transformer_width: 512
07/25/2024 18:10:44 - WARNING -   	 transformer_heads: 8
07/25/2024 18:10:44 - WARNING -   	 transformer_layers: 12
07/25/2024 18:10:44 - WARNING -   		 linear_patch: 2d
07/25/2024 18:10:44 - WARNING -   	 cut_top_layer: 0
07/25/2024 18:10:45 - WARNING -   	 sim_header: meanP
07/25/2024 18:10:48 - INFO -   --------------------
07/25/2024 18:10:48 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 18:10:49 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:10:49 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:10:49 - INFO -   ***** Running test *****
07/25/2024 18:10:49 - INFO -     Num examples = 24
07/25/2024 18:10:49 - INFO -     Batch size = 16
07/25/2024 18:10:49 - INFO -     Num steps = 2
07/25/2024 18:10:49 - INFO -   ***** Running val *****
07/25/2024 18:10:49 - INFO -     Num examples = 6
07/25/2024 18:10:49 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:10:49 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 18:10:49 - INFO -   ***** Running training *****
07/25/2024 18:10:49 - INFO -     Num examples = 90
07/25/2024 18:10:49 - INFO -     Batch size = 18
07/25/2024 18:10:49 - INFO -     Num steps = 100



 30%|████████████▌                             | 3/10 [00:13<00:31,  4.50s/it]
Traceback (most recent call last):
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 753, in <module>
    main()
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 713, in main
    tr_loss, global_step = train_epoch(epoch, args, model, train_dataloader, device, n_gpu, optimizer,
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 347, in train_epoch
    loss = model(input_ids, segment_ids, input_mask, video, video_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 266, in forward
    sim_matrix, *_tmp = self.get_similarity_logits(sequence_output, visual_output, attention_mask, video_mask,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 454, in get_similarity_logits
    retrieve_logits = self._loose_similarity(sequence_output, visual_output, attention_mask, video_mask, sim_header=self.sim_header)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 390, in _loose_similarity
    torch.distributed.barrier()
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 3943, in barrier
    work.wait()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 753, in <module>
[rank0]:     main()
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 713, in main
[rank0]:     tr_loss, global_step = train_epoch(epoch, args, model, train_dataloader, device, n_gpu, optimizer,
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 347, in train_epoch
[rank0]:     loss = model(input_ids, segment_ids, input_mask, video, video_mask)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 266, in forward
[rank0]:     sim_matrix, *_tmp = self.get_similarity_logits(sequence_output, visual_output, attention_mask, video_mask,
[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 454, in get_similarity_logits
[rank0]:     retrieve_logits = self._loose_similarity(sequence_output, visual_output, attention_mask, video_mask, sim_header=self.sim_header)
[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 390, in _loose_similarity
[rank0]:     torch.distributed.barrier()
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 3943, in barrier
[rank0]:     work.wait()
[rank0]: KeyboardInterrupt