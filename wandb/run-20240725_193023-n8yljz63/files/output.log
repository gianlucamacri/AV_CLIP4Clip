07/25/2024 19:30:26 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 19:30:26 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 19:30:26 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 19:30:26 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 19:30:26 - WARNING -   Test retrieval by loose type.
07/25/2024 19:30:26 - WARNING -   	 embed_dim: 512
07/25/2024 19:30:26 - WARNING -   	 image_resolution: 224
07/25/2024 19:30:26 - WARNING -   	 vision_layers: 12
07/25/2024 19:30:26 - WARNING -   	 vision_width: 768
07/25/2024 19:30:26 - WARNING -   	 vision_patch_size: 32
07/25/2024 19:30:26 - WARNING -   	 context_length: 77
07/25/2024 19:30:26 - WARNING -   	 vocab_size: 49408
07/25/2024 19:30:26 - WARNING -   	 transformer_width: 512
07/25/2024 19:30:26 - WARNING -   	 transformer_heads: 8
07/25/2024 19:30:26 - WARNING -   	 transformer_layers: 12
07/25/2024 19:30:26 - WARNING -   		 linear_patch: 2d
07/25/2024 19:30:26 - WARNING -   	 cut_top_layer: 0
07/25/2024 19:30:27 - WARNING -   	 sim_header: meanP
Traceback (most recent call last):
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 757, in <module>
    main()
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 625, in main
    model = init_model(args, device, args.n_gpu, args.local_rank)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 262, in init_model
    model = CLIP4Clip.from_pretrained(args.cross_model, cache_dir=cache_dir, state_dict=model_state_dict, task_config=args)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 52, in from_pretrained
    model = cls(cross_config, clip_state_dict, *inputs, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 247, in __init__
    self.apply(self.init_weights)
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  [Previous line repeated 3 more times]
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/until_module.py", line 76, in init_weights
    module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 757, in <module>
[rank0]:     main()
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 625, in main
[rank0]:     model = init_model(args, device, args.n_gpu, args.local_rank)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 262, in init_model
[rank0]:     model = CLIP4Clip.from_pretrained(args.cross_model, cache_dir=cache_dir, state_dict=model_state_dict, task_config=args)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 52, in from_pretrained
[rank0]:     model = cls(cross_config, clip_state_dict, *inputs, **kwargs)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/modeling.py", line 247, in __init__
[rank0]:     self.apply(self.init_weights)
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
[rank0]:     module.apply(fn)
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
[rank0]:     module.apply(fn)
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 895, in apply
[rank0]:     module.apply(fn)
[rank0]:   [Previous line repeated 3 more times]
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/nn/modules/module.py", line 896, in apply
[rank0]:     fn(self)
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/until_module.py", line 76, in init_weights
[rank0]:     module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)
[rank0]: KeyboardInterrupt