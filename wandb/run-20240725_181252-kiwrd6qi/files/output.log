07/25/2024 18:12:54 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 18:12:54 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 18:12:54 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 18:12:54 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 18:12:54 - WARNING -   Test retrieval by loose type.
07/25/2024 18:12:54 - WARNING -   	 embed_dim: 512
07/25/2024 18:12:54 - WARNING -   	 image_resolution: 224
07/25/2024 18:12:54 - WARNING -   	 vision_layers: 12
07/25/2024 18:12:54 - WARNING -   	 vision_width: 768
07/25/2024 18:12:54 - WARNING -   	 vision_patch_size: 16
07/25/2024 18:12:54 - WARNING -   	 context_length: 77
07/25/2024 18:12:54 - WARNING -   	 vocab_size: 49408
07/25/2024 18:12:54 - WARNING -   	 transformer_width: 512
07/25/2024 18:12:54 - WARNING -   	 transformer_heads: 8
07/25/2024 18:12:54 - WARNING -   	 transformer_layers: 12
07/25/2024 18:12:54 - WARNING -   		 linear_patch: 2d
07/25/2024 18:12:54 - WARNING -   	 cut_top_layer: 0
07/25/2024 18:12:55 - WARNING -   	 sim_header: meanP
07/25/2024 18:12:59 - INFO -   --------------------
07/25/2024 18:12:59 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 18:13:00 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:13:00 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:13:00 - INFO -   ***** Running test *****
07/25/2024 18:13:00 - INFO -     Num examples = 24
07/25/2024 18:13:00 - INFO -     Batch size = 16
07/25/2024 18:13:00 - INFO -     Num steps = 2
07/25/2024 18:13:00 - INFO -   ***** Running val *****
07/25/2024 18:13:00 - INFO -     Num examples = 6
07/25/2024 18:13:00 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:13:00 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 18:13:00 - INFO -   ***** Running training *****
07/25/2024 18:13:00 - INFO -     Num examples = 90
07/25/2024 18:13:00 - INFO -     Batch size = 18
07/25/2024 18:13:00 - INFO -     Num steps = 100









100%|█████████████████████████████████████████| 10/10 [00:39<00:00,  3.95s/it]
07/25/2024 18:13:39 - INFO -   Epoch 1/10 Finished, Train Loss: 0.325705
07/25/2024 18:13:40 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.0
07/25/2024 18:13:40 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_opt.bin.0
07/25/2024 18:13:40 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:13:42 - INFO -   retrieval of video 16 took 2.3075431250035763
07/25/2024 18:13:42 - INFO -   computation took 0.033488951972685754
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.34s/it]
0/1
07/25/2024 18:13:44 - INFO -   sim matrix size: 6, 6
07/25/2024 18:13:44 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:13:44 - INFO -   Similarity loss: 1.6
07/25/2024 18:13:44 - INFO -   Text-to-Video:
07/25/2024 18:13:44 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:13:44 - INFO -   Video-to-Text:
07/25/2024 18:13:44 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:13:44 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.0, its metric is: 1.5902









100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.85s/it]
07/25/2024 18:14:22 - INFO -   Epoch 2/10 Finished, Train Loss: 0.240245
07/25/2024 18:14:23 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.1
07/25/2024 18:14:23 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_opt.bin.1
07/25/2024 18:14:23 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:14:25 - INFO -   retrieval of video 16 took 2.2722655760589987
07/25/2024 18:14:25 - INFO -   computation took 0.032416232977993786
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.30s/it]
07/25/2024 18:14:25 - INFO -   sim matrix size: 6, 6
07/25/2024 18:14:25 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:14:25 - INFO -   Similarity loss: 1.6
07/25/2024 18:14:25 - INFO -   Text-to-Video:
07/25/2024 18:14:25 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:14:25 - INFO -   Video-to-Text:
07/25/2024 18:14:25 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:14:25 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.1, its metric is: 1.5853









100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.85s/it]
07/25/2024 18:15:04 - INFO -   Epoch 3/10 Finished, Train Loss: 0.128749
07/25/2024 18:15:05 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.2
07/25/2024 18:15:05 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_opt.bin.2
07/25/2024 18:15:05 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 18:15:07 - INFO -   retrieval of video 16 took 2.2842417450156063
07/25/2024 18:15:07 - INFO -   computation took 0.03322565497364849
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]
07/25/2024 18:15:07 - INFO -   sim matrix size: 6, 6
07/25/2024 18:15:07 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 18:15:07 - INFO -   Similarity loss: 1.6
07/25/2024 18:15:07 - INFO -   Text-to-Video:
07/25/2024 18:15:07 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:15:07 - INFO -   Video-to-Text:
07/25/2024 18:15:07 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:15:07 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.2, its metric is: 1.5817









100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.88s/it]
07/25/2024 18:15:46 - INFO -   Epoch 4/10 Finished, Train Loss: 0.089160
07/25/2024 18:15:47 - INFO -   Model saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.3
07/25/2024 18:15:47 - INFO -   Optimizer saved to ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_opt.bin.3
07/25/2024 18:15:47 - INFO -   Eval on val dataset
07/25/2024 18:15:49 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 18:15:49 - INFO -   retrieval of video 16 took 2.3178911530412734
07/25/2024 18:15:49 - INFO -   computation took 0.03231821197550744
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]
07/25/2024 18:15:49 - INFO -   sim matrix size: 6, 6
07/25/2024 18:15:49 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 18:15:49 - INFO -   retrieval of video 16 took 2.3178911530412734
07/25/2024 18:15:49 - INFO -   Similarity loss: 1.6
07/25/2024 18:15:49 - INFO -   Text-to-Video:
07/25/2024 18:15:49 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 18:15:49 - INFO -   Video-to-Text:
07/25/2024 18:15:49 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 18:15:49 - INFO -   The best model according to loss strategy is: ../ckpts/av_retreival_lr2e-05_e10_b18_26fps_loss_42_1721923971_test/pytorch_model.bin.3, its metric is: 1.5692
 10%|████▏                                     | 1/10 [00:03<00:31,  3.52s/it]
 20%|████████▍                                 | 2/10 [00:07<00:30,  3.75s/it]
 30%|████████████▌                             | 3/10 [00:11<00:27,  3.95s/it]
 40%|████████████████▊                         | 4/10 [00:14<00:21,  3.65s/it]
 50%|█████████████████████                     | 5/10 [00:20<00:21,  4.39s/it]
 60%|█████████████████████████▏                | 6/10 [00:24<00:16,  4.11s/it]
 70%|█████████████████████████████▍            | 7/10 [00:27<00:11,  3.75s/it]
 80%|█████████████████████████████████▌        | 8/10 [00:30<00:07,  3.73s/it]
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.85s/it]
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.85s/it]07/25/2024 18:16:28 - INFO -   Epoch: 5/10, Step: 10/10, Lr: , Loss: 0.001725, Time/step: 0.772383
  0%|                                                  | 0/10 [00:00<?, ?it/s]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 10%|████▏                                     | 1/10 [00:04<00:43,  4.79s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 20%|████████▍                                 | 2/10 [00:07<00:30,  3.86s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 30%|████████████▌                             | 3/10 [00:11<00:26,  3.79s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 40%|████████████████▊                         | 4/10 [00:15<00:23,  3.98s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 50%|█████████████████████                     | 5/10 [00:19<00:19,  3.82s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 60%|█████████████████████████▏                | 6/10 [00:24<00:17,  4.33s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 70%|█████████████████████████████▍            | 7/10 [00:28<00:12,  4.04s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 80%|█████████████████████████████████▌        | 8/10 [00:31<00:07,  3.83s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.60s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.89s/it]07/25/2024 18:16:31 - INFO -   retrieval of video 16 took 2.29449348594062035, Time/step: 0.772383
  0%|                                                  | 0/10 [00:00<?, ?it/s]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 10%|████▏                                     | 1/10 [00:03<00:27,  3.04s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 20%|████████▍                                 | 2/10 [00:07<00:31,  3.90s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 30%|████████████▌                             | 3/10 [00:12<00:29,  4.16s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 40%|████████████████▊                         | 4/10 [00:15<00:24,  4.05s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 50%|█████████████████████                     | 5/10 [00:19<00:19,  3.85s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 60%|█████████████████████████▏                | 6/10 [00:23<00:16,  4.02s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 70%|█████████████████████████████▍            | 7/10 [00:27<00:12,  4.00s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 80%|█████████████████████████████████▌        | 8/10 [00:31<00:07,  3.79s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.65s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.86s/it]07/25/2024 18:17:14 - INFO -   retrieval of video 16 took 2.28159071307163735, Time/step: 0.772383
  0%|                                                  | 0/10 [00:00<?, ?it/s]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 10%|████▏                                     | 1/10 [00:03<00:31,  3.53s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 20%|████████▍                                 | 2/10 [00:06<00:26,  3.31s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 30%|████████████▌                             | 3/10 [00:10<00:25,  3.63s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 40%|████████████████▊                         | 4/10 [00:15<00:24,  4.16s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 50%|█████████████████████                     | 5/10 [00:18<00:18,  3.74s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 60%|█████████████████████████▏                | 6/10 [00:23<00:16,  4.11s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 70%|█████████████████████████████▍            | 7/10 [00:27<00:12,  4.18s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 80%|█████████████████████████████████▌        | 8/10 [00:31<00:08,  4.07s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.59s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.84s/it]07/25/2024 18:17:56 - INFO -   retrieval of video 16 took 2.30210641899611835, Time/step: 0.772383
  0%|                                                  | 0/10 [00:00<?, ?it/s]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 10%|████▏                                     | 1/10 [00:03<00:31,  3.51s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 20%|████████▍                                 | 2/10 [00:07<00:28,  3.52s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 30%|████████████▌                             | 3/10 [00:11<00:26,  3.84s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 40%|████████████████▊                         | 4/10 [00:17<00:27,  4.60s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 50%|█████████████████████                     | 5/10 [00:20<00:20,  4.11s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 60%|█████████████████████████▏                | 6/10 [00:24<00:16,  4.07s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 70%|█████████████████████████████▍            | 7/10 [00:27<00:11,  3.75s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 80%|█████████████████████████████████▌        | 8/10 [00:32<00:08,  4.09s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.69s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
100%|█████████████████████████████████████████| 10/10 [00:38<00:00,  3.85s/it]07/25/2024 18:18:37 - INFO -   retrieval of video 16 took 2.31094286602456125, Time/step: 0.772383
  0%|                                                  | 0/10 [00:00<?, ?it/s]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 10%|████▏                                     | 1/10 [00:03<00:34,  3.81s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 20%|████████▍                                 | 2/10 [00:07<00:32,  4.02s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 30%|████████████▌                             | 3/10 [00:10<00:23,  3.37s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 40%|████████████████▊                         | 4/10 [00:15<00:24,  4.08s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 50%|█████████████████████                     | 5/10 [00:19<00:19,  3.94s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 60%|█████████████████████████▏                | 6/10 [00:23<00:15,  3.96s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 70%|█████████████████████████████▍            | 7/10 [00:28<00:12,  4.23s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 80%|█████████████████████████████████▌        | 8/10 [00:31<00:08,  4.02s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.74s/it]07/25/2024 18:19:19 - INFO -   retrieval of video 16 took 2.29876929498277625, Time/step: 0.772383
 90%|█████████████████████████████████████▊    | 9/10 [00:34<00:03,  3.74s/it]07/25/2024 18:19:58 - INFO -   Epoch: 10/10, Step: 10/10, Lr: , Loss: 0.009719, Time/step: 0.774822
07/25/2024 18:20:02 - WARNING -   	 image_resolution: 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:20:03 - WARNING -   	 sim_header: meanP 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:20:03 - WARNING -   	 sim_header: meanP 224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

0/2

07/25/2024 18:20:14 - INFO -   sim matrix size: 24, 24224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 18:20:14 - INFO -   sim matrix size: 24, 24224val.py:321: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.