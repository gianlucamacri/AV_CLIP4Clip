07/25/2024 18:37:05 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 18:37:05 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 18:37:05 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 18:37:05 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 18:37:05 - WARNING -   Test retrieval by loose type.
07/25/2024 18:37:05 - WARNING -   	 embed_dim: 512
07/25/2024 18:37:05 - WARNING -   	 image_resolution: 224
07/25/2024 18:37:05 - WARNING -   	 vision_layers: 12
07/25/2024 18:37:05 - WARNING -   	 vision_width: 768
07/25/2024 18:37:05 - WARNING -   	 vision_patch_size: 32
07/25/2024 18:37:05 - WARNING -   	 context_length: 77
07/25/2024 18:37:05 - WARNING -   	 vocab_size: 49408
07/25/2024 18:37:05 - WARNING -   	 transformer_width: 512
07/25/2024 18:37:05 - WARNING -   	 transformer_heads: 8
07/25/2024 18:37:05 - WARNING -   	 transformer_layers: 12
07/25/2024 18:37:05 - WARNING -   		 linear_patch: 2d
07/25/2024 18:37:05 - WARNING -   	 cut_top_layer: 0
07/25/2024 18:37:06 - WARNING -   	 sim_header: meanP
07/25/2024 18:37:09 - INFO -   --------------------
07/25/2024 18:37:09 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 18:37:10 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:37:10 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:37:10 - INFO -   ***** Running test *****
07/25/2024 18:37:10 - INFO -     Num examples = 24
07/25/2024 18:37:10 - INFO -     Batch size = 150
07/25/2024 18:37:10 - INFO -     Num steps = 1
07/25/2024 18:37:10 - INFO -   ***** Running val *****
07/25/2024 18:37:10 - INFO -     Num examples = 6
07/25/2024 18:37:10 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 18:37:10 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 18:37:10 - INFO -   ***** Running training *****
07/25/2024 18:37:10 - INFO -     Num examples = 90
07/25/2024 18:37:10 - INFO -     Batch size = 30
07/25/2024 18:37:10 - INFO -     Num steps = 30

 33%|██████████████▎                            | 1/3 [00:13<00:26, 13.03s/it]
Traceback (most recent call last):
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 751, in <module>
    main()
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 711, in main
    tr_loss, global_step = train_epoch(epoch, args, model, train_dataloader, device, args.n_gpu, optimizer,
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 339, in train_epoch
    for step, batch in enumerate(tqdm(train_dataloader)):
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/dataloader_artistic_videos_retreival.py", line 159, in __getitem__
    video, video_mask = self._get_rawvideo(choice_video_ids)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/dataloader_artistic_videos_retreival.py", line 121, in _get_rawvideo
    raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/rawvideo_util.py", line 133, in get_video_data
    image_input = {'video':th.tensor(np.load(f))}
                                     ^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/npyio.py", line 456, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/format.py", line 831, in read_array
    data = _read_bytes(fp, read_size, "array data")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/format.py", line 966, in _read_bytes
    r = fp.read(size - len(data))
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/_compression.py", line 68, in readinto
    data = self.read(len(byte_view))
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/gzip.py", line 537, in read
    uncompress = self._decompressor.decompress(b"", size)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 751, in <module>
[rank0]:     main()
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 711, in main
[rank0]:     tr_loss, global_step = train_epoch(epoch, args, model, train_dataloader, device, args.n_gpu, optimizer,
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py", line 339, in train_epoch
[rank0]:     for step, batch in enumerate(tqdm(train_dataloader)):
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/tqdm/std.py", line 1181, in __iter__
[rank0]:     for obj in iterable:
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:     data = self._next_data()
[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
[rank0]:     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:             ~~~~~~~~~~~~^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/dataloader_artistic_videos_retreival.py", line 159, in __getitem__
[rank0]:     video, video_mask = self._get_rawvideo(choice_video_ids)
[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/dataloader_artistic_videos_retreival.py", line 121, in _get_rawvideo
[rank0]:     raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/tesiMagistrale/AV_CLIP4Clip/dataloaders/rawvideo_util.py", line 133, in get_video_data
[rank0]:     image_input = {'video':th.tensor(np.load(f))}
[rank0]:                                      ^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/npyio.py", line 456, in load
[rank0]:     return format.read_array(fid, allow_pickle=allow_pickle,
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/format.py", line 831, in read_array
[rank0]:     data = _read_bytes(fp, read_size, "array data")
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/site-packages/numpy/lib/format.py", line 966, in _read_bytes
[rank0]:     r = fp.read(size - len(data))
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/gzip.py", line 324, in read
[rank0]:     return self._buffer.read(size)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/_compression.py", line 68, in readinto
[rank0]:     data = self.read(len(byte_view))
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gmacri/anaconda3/envs/clip/lib/python3.12/gzip.py", line 537, in read
[rank0]:     uncompress = self._decompressor.decompress(b"", size)
[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: KeyboardInterrupt