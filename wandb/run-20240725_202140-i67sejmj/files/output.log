07/25/2024 20:21:42 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 20:21:42 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 20:21:42 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 20:21:42 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 20:21:42 - WARNING -   Test retrieval by loose type.
07/25/2024 20:21:42 - WARNING -   	 embed_dim: 512
07/25/2024 20:21:42 - WARNING -   	 image_resolution: 224
07/25/2024 20:21:42 - WARNING -   	 vision_layers: 12
07/25/2024 20:21:42 - WARNING -   	 vision_width: 768
07/25/2024 20:21:42 - WARNING -   	 vision_patch_size: 32
07/25/2024 20:21:42 - WARNING -   	 context_length: 77
07/25/2024 20:21:42 - WARNING -   	 vocab_size: 49408
07/25/2024 20:21:42 - WARNING -   	 transformer_width: 512
07/25/2024 20:21:42 - WARNING -   	 transformer_heads: 8
07/25/2024 20:21:42 - WARNING -   	 transformer_layers: 12
07/25/2024 20:21:42 - WARNING -   		 linear_patch: 2d
07/25/2024 20:21:42 - WARNING -   	 cut_top_layer: 0
07/25/2024 20:21:43 - WARNING -   	 sim_header: meanP
07/25/2024 20:21:46 - INFO -   --------------------
07/25/2024 20:21:46 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 20:21:47 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 20:21:47 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 20:21:47 - INFO -   ***** Running test *****
07/25/2024 20:21:47 - INFO -     Num examples = 24
07/25/2024 20:21:47 - INFO -     Batch size = 16
07/25/2024 20:21:47 - INFO -     Num steps = 2
07/25/2024 20:21:47 - INFO -   ***** Running val *****
07/25/2024 20:21:47 - INFO -     Num examples = 6
07/25/2024 20:21:47 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 20:21:47 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 20:21:47 - INFO -   ***** Running training *****
07/25/2024 20:21:47 - INFO -     Num examples = 90
07/25/2024 20:21:47 - INFO -     Batch size = 30
07/25/2024 20:21:47 - INFO -     Num steps = 36


100%|███████████████████████████████████████████| 3/3 [00:33<00:00, 11.05s/it]
07/25/2024 20:22:21 - INFO -   Epoch 1/12 Finished, Train Loss: 0.720257
07/25/2024 20:22:21 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.0
07/25/2024 20:22:21 - INFO -   Optimizer saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_opt.bin.0
07/25/2024 20:22:21 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 20:22:24 - INFO -   retrieval of video 16 took 2.1981494689825922
07/25/2024 20:22:24 - INFO -   computation took 0.03233950608409941
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]
07/25/2024 20:22:24 - INFO -   sim matrix size: 6, 6
07/25/2024 20:22:24 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 20:22:24 - INFO -   Similarity loss: 1.6
07/25/2024 20:22:24 - INFO -   Text-to-Video:
07/25/2024 20:22:24 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.7
07/25/2024 20:22:24 - INFO -   Video-to-Text:
07/25/2024 20:22:24 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 20:22:24 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.0, its metric is: 1.6235


100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.70s/it]
07/25/2024 20:22:56 - INFO -   Epoch 2/12 Finished, Train Loss: 0.703750
07/25/2024 20:22:57 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.1
07/25/2024 20:22:57 - INFO -   Optimizer saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_opt.bin.1
07/25/2024 20:22:57 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 20:22:59 - INFO -   retrieval of video 16 took 2.231010660994798
07/25/2024 20:22:59 - INFO -   computation took 0.03124080307316035
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]
07/25/2024 20:22:59 - INFO -   sim matrix size: 6, 6
07/25/2024 20:22:59 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 20:22:59 - INFO -   Similarity loss: 1.3
07/25/2024 20:22:59 - INFO -   Text-to-Video:
07/25/2024 20:22:59 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.2
07/25/2024 20:22:59 - INFO -   Video-to-Text:
07/25/2024 20:22:59 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 20:22:59 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.1, its metric is: 1.3023


100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.81s/it]
07/25/2024 20:23:31 - INFO -   Epoch 3/12 Finished, Train Loss: 0.649377
07/25/2024 20:23:32 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.2
07/25/2024 20:23:32 - INFO -   Optimizer saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_opt.bin.2
07/25/2024 20:23:32 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 20:23:35 - INFO -   retrieval of video 16 took 2.2255132130812854
07/25/2024 20:23:35 - INFO -   computation took 0.03144656796939671
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]
07/25/2024 20:23:35 - INFO -   sim matrix size: 6, 6
07/25/2024 20:23:35 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 20:23:35 - INFO -   Similarity loss: 1.5
07/25/2024 20:23:35 - INFO -   Text-to-Video:
07/25/2024 20:23:35 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.7
07/25/2024 20:23:35 - INFO -   Video-to-Text:
07/25/2024 20:23:35 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 20:23:35 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.1, its metric is: 1.3023


100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:24:07 - INFO -   Epoch 4/12 Finished, Train Loss: 0.527403
07/25/2024 20:24:08 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.3
07/25/2024 20:24:08 - INFO -   Optimizer saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_opt.bin.3
07/25/2024 20:24:08 - INFO -   Eval on val dataset
07/25/2024 20:24:10 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 20:24:10 - INFO -   retrieval of video 16 took 2.227794563048519
07/25/2024 20:24:10 - INFO -   computation took 0.03148498700466007
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]
07/25/2024 20:24:10 - INFO -   sim matrix size: 6, 6
07/25/2024 20:24:10 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 20:24:10 - INFO -   retrieval of video 16 took 2.227794563048519
07/25/2024 20:24:10 - INFO -   Similarity loss: 1.4
07/25/2024 20:24:10 - INFO -   Text-to-Video:
07/25/2024 20:24:10 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 20:24:10 - INFO -   Video-to-Text:
07/25/2024 20:24:10 - INFO -   	>>>  V2T$R@1: 83.3 - V2T$R@5: 83.3 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.8
07/25/2024 20:24:10 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.1, its metric is: 1.3023
 33%|██████████████▎                            | 1/3 [00:10<00:20, 10.25s/it]
 67%|████████████████████████████▋              | 2/3 [00:21<00:10, 10.90s/it]
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.77s/it]
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:24:46 - INFO -   Text-to-Video:███| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:24:46 - INFO -   Text-to-Video:███| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:24:46 - INFO -   Text-to-Video:███| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:24:46 - INFO -   Text-to-Video:███| 3/3 [00:32<00:00, 10.77s/it]
07/25/2024 20:25:21 - INFO -   computation took 0.03099381201900541810.77s/it]
07/25/2024 20:25:21 - INFO -   computation took 0.03099381201900541810.77s/it]
07/25/2024 20:25:21 - INFO -   computation took 0.03099381201900541810.77s/it]
07/25/2024 20:25:54 - INFO -   Epoch 7/12 Finished, Train Loss: 0.2563667s/it]
07/25/2024 20:25:57 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.5
07/25/2024 20:25:57 - INFO -   	>>>  R@1: 83.3 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.5
 67%|████████████████████████████▋              | 2/3 [00:22<00:11, 11.65s/it]dian R: 1.0 - Mean R: 1.5
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.70s/it]dian R: 1.0 - Mean R: 1.5
07/25/2024 20:26:30 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.7
  0%|                                                   | 0/3 [00:00<?, ?it/s]07/25/2024 20:26:32 - INFO -   retrieval of video 16 took 2.2229465460404754
 33%|██████████████▎                            | 1/3 [00:10<00:20, 10.27s/it]07/25/2024 20:26:32 - INFO -   retrieval of video 16 took 2.2229465460404754
 67%|████████████████████████████▋              | 2/3 [00:22<00:11, 11.47s/it]07/25/2024 20:26:32 - INFO -   retrieval of video 16 took 2.2229465460404754
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.76s/it]07/25/2024 20:26:32 - INFO -   retrieval of video 16 took 2.2229465460404754
  0%|                                                   | 0/3 [00:00<?, ?it/s]07/25/2024 20:27:07 - INFO -   retrieval of video 16 took 2.2218458179850134
 33%|██████████████▎                            | 1/3 [00:11<00:22, 11.06s/it]07/25/2024 20:27:07 - INFO -   retrieval of video 16 took 2.2218458179850134
 67%|████████████████████████████▋              | 2/3 [00:22<00:11, 11.02s/it]07/25/2024 20:27:07 - INFO -   retrieval of video 16 took 2.2218458179850134
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.71s/it]07/25/2024 20:27:07 - INFO -   retrieval of video 16 took 2.2218458179850134
  0%|                                                   | 0/3 [00:00<?, ?it/s]07/25/2024 20:27:43 - INFO -   retrieval of video 16 took 2.2113912099739537
 33%|██████████████▎                            | 1/3 [00:10<00:21, 10.61s/it]07/25/2024 20:27:43 - INFO -   retrieval of video 16 took 2.2113912099739537
 67%|████████████████████████████▋              | 2/3 [00:22<00:11, 11.55s/it]07/25/2024 20:27:43 - INFO -   retrieval of video 16 took 2.2113912099739537
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.70s/it]07/25/2024 20:27:43 - INFO -   retrieval of video 16 took 2.2113912099739537
07/25/2024 20:28:16 - INFO -   Model saved to ckpts/av_retreival_lr2e-05_e12_b30_24fps_loss_42_1721931699_test/pytorch_model.bin.10took 2.2113912099739537
  0%|                                                   | 0/3 [00:00<?, ?it/s]07/25/2024 20:28:18 - INFO -   retrieval of video 16 took 2.1459716330282397
 33%|██████████████▎                            | 1/3 [00:09<00:18,  9.17s/it]07/25/2024 20:28:18 - INFO -   retrieval of video 16 took 2.1459716330282397
 67%|████████████████████████████▋              | 2/3 [00:22<00:11, 11.35s/it]07/25/2024 20:28:18 - INFO -   retrieval of video 16 took 2.1459716330282397
100%|███████████████████████████████████████████| 3/3 [00:32<00:00, 10.71s/it]07/25/2024 20:28:18 - INFO -   retrieval of video 16 took 2.1459716330282397
/home/gmacri/tesiMagistrale/AV_CLIP4Clip/main_task_retrieval.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 20:28:55 - WARNING -   	 sim_header: meanP 224val.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 20:28:55 - WARNING -   	 sim_header: meanP 224val.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 20:28:55 - WARNING -   	 sim_header: meanP 224val.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

07/25/2024 20:29:05 - INFO -   sim matrix size: 24, 24224val.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 20:29:05 - INFO -   sim matrix size: 24, 24224val.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.