07/25/2024 19:19:13 - INFO -   loading archive file /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base
07/25/2024 19:19:13 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}
07/25/2024 19:19:13 - INFO -   Weight doesn't exsits. /home/gmacri/tesiMagistrale/AV_CLIP4Clip/modules/cross-base/cross_pytorch_model.bin
07/25/2024 19:19:13 - WARNING -   Stage-One:True, Stage-Two:False
07/25/2024 19:19:13 - WARNING -   Test retrieval by loose type.
07/25/2024 19:19:13 - WARNING -   	 embed_dim: 512
07/25/2024 19:19:13 - WARNING -   	 image_resolution: 224
07/25/2024 19:19:13 - WARNING -   	 vision_layers: 12
07/25/2024 19:19:13 - WARNING -   	 vision_width: 768
07/25/2024 19:19:13 - WARNING -   	 vision_patch_size: 32
07/25/2024 19:19:13 - WARNING -   	 context_length: 77
07/25/2024 19:19:13 - WARNING -   	 vocab_size: 49408
07/25/2024 19:19:13 - WARNING -   	 transformer_width: 512
07/25/2024 19:19:13 - WARNING -   	 transformer_heads: 8
07/25/2024 19:19:13 - WARNING -   	 transformer_layers: 12
07/25/2024 19:19:13 - WARNING -   		 linear_patch: 2d
07/25/2024 19:19:13 - WARNING -   	 cut_top_layer: 0
07/25/2024 19:19:14 - WARNING -   	 sim_header: meanP
07/25/2024 19:19:17 - INFO -   --------------------
07/25/2024 19:19:17 - INFO -   Weights from pretrained model not used in CLIP4Clip:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
07/25/2024 19:19:18 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 19:19:18 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 19:19:18 - INFO -   ***** Running test *****
07/25/2024 19:19:18 - INFO -     Num examples = 24
07/25/2024 19:19:18 - INFO -     Batch size = 16
07/25/2024 19:19:18 - INFO -     Num steps = 2
07/25/2024 19:19:18 - INFO -   ***** Running val *****
07/25/2024 19:19:18 - INFO -     Num examples = 6
07/25/2024 19:19:18 - INFO -   updating metadata video filename paths to match the actual location, to prevent this behavior set the updateVideoFilenames to false
07/25/2024 19:19:18 - INFO -   0 (0.0 %) will remain unsued for each epoch due to drop last set to true for the dataloader
07/25/2024 19:19:18 - INFO -   ***** Running training *****
07/25/2024 19:19:18 - INFO -     Num examples = 90
07/25/2024 19:19:18 - INFO -     Batch size = 30
07/25/2024 19:19:18 - INFO -     Num steps = 36





100%|███████████████████████████████████████████| 6/6 [00:36<00:00,  6.16s/it]
07/25/2024 19:19:55 - INFO -   Epoch 1/6 Finished, Train Loss: 0.431188
07/25/2024 19:19:56 - INFO -   Model saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.0
07/25/2024 19:19:56 - INFO -   Optimizer saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_opt.bin.0
07/25/2024 19:19:56 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 19:19:58 - INFO -   retrieval of video 16 took 2.3253659510519356
07/25/2024 19:19:59 - INFO -   computation took 0.047052208916284144
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]
07/25/2024 19:20:00 - INFO -   sim matrix size: 6, 6
07/25/2024 19:20:00 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 19:20:00 - INFO -   Similarity loss: 0.9
07/25/2024 19:20:00 - INFO -   Text-to-Video:
07/25/2024 19:20:00 - INFO -   	>>>  R@1: 66.7 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 19:20:00 - INFO -   Video-to-Text:
07/25/2024 19:20:00 - INFO -   	>>>  V2T$R@1: 66.7 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.3
07/25/2024 19:20:00 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.0, its metric is: 0.8736





100%|███████████████████████████████████████████| 6/6 [00:36<00:00,  6.04s/it]
07/25/2024 19:20:36 - INFO -   Epoch 2/6 Finished, Train Loss: 0.858147
07/25/2024 19:20:37 - INFO -   Model saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.1
07/25/2024 19:20:37 - INFO -   Optimizer saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_opt.bin.1
07/25/2024 19:20:37 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 19:20:39 - INFO -   retrieval of video 16 took 2.260734779993072
07/25/2024 19:20:39 - INFO -   computation took 0.04731995891779661
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.31s/it]
07/25/2024 19:20:39 - INFO -   sim matrix size: 6, 6
07/25/2024 19:20:39 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 19:20:39 - INFO -   Similarity loss: 0.9
07/25/2024 19:20:39 - INFO -   Text-to-Video:
07/25/2024 19:20:39 - INFO -   	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
07/25/2024 19:20:39 - INFO -   Video-to-Text:
07/25/2024 19:20:39 - INFO -   	>>>  V2T$R@1: 50.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.5 - V2T$Mean R: 1.7
07/25/2024 19:20:39 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.0, its metric is: 0.8736





100%|███████████████████████████████████████████| 6/6 [00:36<00:00,  6.05s/it]
07/25/2024 19:21:16 - INFO -   Epoch 3/6 Finished, Train Loss: 0.988598
07/25/2024 19:21:16 - INFO -   Model saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.2
07/25/2024 19:21:16 - INFO -   Optimizer saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_opt.bin.2
07/25/2024 19:21:16 - INFO -   Eval on val dataset
  0%|                                                   | 0/1 [00:00<?, ?it/s]07/25/2024 19:21:19 - INFO -   retrieval of video 16 took 2.294146655010991
07/25/2024 19:21:19 - INFO -   computation took 0.048493240028619766
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.34s/it]
07/25/2024 19:21:19 - INFO -   sim matrix size: 6, 6
07/25/2024 19:21:19 - INFO -   	 Length-T: 6, Length-V:6
07/25/2024 19:21:19 - INFO -   Similarity loss: 1.2
07/25/2024 19:21:19 - INFO -   Text-to-Video:
07/25/2024 19:21:19 - INFO -   	>>>  R@1: 66.7 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.3
07/25/2024 19:21:19 - INFO -   Video-to-Text:
07/25/2024 19:21:19 - INFO -   	>>>  V2T$R@1: 66.7 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.7
07/25/2024 19:21:19 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.0, its metric is: 0.8736





100%|███████████████████████████████████████████| 6/6 [00:35<00:00,  5.99s/it]
07/25/2024 19:21:55 - INFO -   Epoch 4/6 Finished, Train Loss: 0.581635
07/25/2024 19:21:56 - INFO -   Model saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.3
07/25/2024 19:21:56 - INFO -   Optimizer saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_opt.bin.3
07/25/2024 19:21:56 - INFO -   Eval on val dataset
07/25/2024 19:21:58 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 19:21:58 - INFO -   retrieval of video 16 took 2.2694643760332838
07/25/2024 19:21:58 - INFO -   computation took 0.046322554000653327
100%|███████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]
07/25/2024 19:21:58 - INFO -   sim matrix size: 6, 6
07/25/2024 19:21:58 - INFO -   	 Length-T: 6, Length-V:6| 0/1 [00:00<?, ?it/s]07/25/2024 19:21:58 - INFO -   retrieval of video 16 took 2.2694643760332838
07/25/2024 19:21:58 - INFO -   Similarity loss: 1.7
07/25/2024 19:21:58 - INFO -   Text-to-Video:
07/25/2024 19:21:58 - INFO -   	>>>  R@1: 66.7 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.5
07/25/2024 19:21:58 - INFO -   Video-to-Text:
07/25/2024 19:21:58 - INFO -   	>>>  V2T$R@1: 50.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.5 - V2T$Mean R: 1.8
07/25/2024 19:21:58 - INFO -   The best model according to loss strategy is: ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.0, its metric is: 0.8736
 17%|███████▏                                   | 1/6 [00:05<00:26,  5.21s/it]
 33%|██████████████▎                            | 2/6 [00:11<00:23,  5.92s/it]
 50%|█████████████████████▌                     | 3/6 [00:19<00:20,  6.71s/it]
 67%|████████████████████████████▋              | 4/6 [00:24<00:11,  5.97s/it]
 83%|███████████████████████████████████▊       | 5/6 [00:30<00:06,  6.01s/it]
100%|███████████████████████████████████████████| 6/6 [00:35<00:00,  6.00s/it]
100%|███████████████████████████████████████████| 6/6 [00:35<00:00,  6.00s/it]
07/25/2024 19:22:38 - INFO -   Text-to-Video:███| 6/6 [00:35<00:00,  6.00s/it]
07/25/2024 19:22:38 - INFO -   Text-to-Video:███| 6/6 [00:35<00:00,  6.00s/it]
07/25/2024 19:22:38 - INFO -   Text-to-Video:███| 6/6 [00:35<00:00,  6.00s/it]
07/25/2024 19:22:38 - INFO -   Text-to-Video:███| 6/6 [00:35<00:00,  6.00s/it]
 67%|████████████████████████████▋              | 4/6 [00:25<00:12,  6.50s/it]
 83%|███████████████████████████████████▊       | 5/6 [00:30<00:05,  5.96s/it]
100%|███████████████████████████████████████████| 6/6 [00:36<00:00,  6.06s/it]
07/25/2024 19:23:15 - INFO -   Model saved to ckpts/av_retreival_lr0.001_e6_b30_48fps_loss_42_1721927950_test/pytorch_model.bin.5
07/25/2024 19:23:18 - WARNING -   	 image_resolution: 224val.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 19:23:19 - WARNING -   	 sim_header: meanP 224val.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 19:23:19 - WARNING -   	 sim_header: meanP 224val.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

0/2

07/25/2024 19:23:30 - INFO -   sim matrix size: 24, 24224val.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
07/25/2024 19:23:30 - INFO -   sim matrix size: 24, 24224val.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.